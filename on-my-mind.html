<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<title>
    Inchan Kim | Educator and Scholar of Digital Technology and Entrepreneurship | On My Mind
  </title>
  <link rel="icon" type="image/png" href="Inchan_favicon.png" />
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="On My Mind: reflections by Inchan Kim, Associate Professor of Information Systems and Digital Entrepreneurship, on research, teaching, and life." name="description"/>
<link href="styles.css" rel="stylesheet"/>
</head>
<body>
<header>
<div class="container top-nav">
<div class="brand">Inchan Kim</div>
<nav class="nav-links">
<a href="index.html">Overview</a>
<a href="research.html">Research for Everyone</a>
<a class="active" href="on-my-mind.html">On My Mind</a>
</nav>
</div>
</header>
<main class="container">
<section>
<h2>On My Mind</h2>
<p>
        This page is a quieter space where I occasionally write about what I am
        thinking—about research, teaching, and life. Nothing here represents the
        official view of any institution; it is simply one human being trying to
        make sense of the world.
      </p>
</section>
<section>
<h2>Recent Thoughts</h2>
<div class="post-list">

<article class="post">
<div class="post-meta">Life · Perspective</div>
<h3>On Calling AI a “General Use Technology”</h3>
<div class="post-date">December 2, 2025</div>

  <p>
    One of my favorite podcasts is <em>The Journal</em> by 
    <em>The Wall Street Journal</em>. But in today’s episode—<a href="https://www.wsj.com/podcasts/the-journal/china-and-the-us-are-in-a-race-for-ai-supremacy/bb7e82b5-c912-4ecd-9f24-8f332a4b7202">
    “China and the U.S. Are in a Race for AI Supremacy”</a>—I heard something that 
    genuinely me.
  </p>

  <p>
    The reporter stated, “This [referring to AI] is the first general use technology 
    we've seen come along since the internet, and so it affects potentially everything.”
  </p>

  <p>
    Comments like this—coming from a reporter for a major newspaper—spread misunderstanding 
    about AI and mislead a wide range of listeners. AI is <strong>not</strong> a “general use 
    technology.” It is not one coherent thing. What we commonly call <em>AI</em> is a sprawling 
    family of techniques, applications, and systems that vary dramatically in purpose, 
    capability, and design.
  </p>

  <p>
    The episode’s underlying narrative is that the U.S. and China are locked in a race 
    to build “artificial general intelligence” (AGI). But is AGI a general-use technology? 
    Only if we define AGI as a system that “knows everything deeply.” Under that definition, 
    a hypothetical future ChatGPT could be called AGI. But such a technology is neither 
    necessary nor even desirable. In many fields—medicine, law, finance—specialized systems 
    already surpass (or will soon surpass) human expertise in <em>narrow</em> domains. 
    What good reason do we have to combine all such domain-specific “intelligent” systems 
    into a single, unified AGI? None.
  </p>

  <p>
    And are those domain-specific intelligent systems “general use technologies”? 
    Again, no. They are built to solve specific problems, operate under specific constraints, 
    and serve specific communities of practice.
  </p>

  <p>
    So here is my plea: <strong>When we talk about AI, we must define—at least conceptually—the specific technology at hand.</strong> You don’t need to list a concrete product or 
    application, but you <em>do</em> need to specify what kind of system you’re referring to. 
    Otherwise, we are speaking in vague abstractions that obscure far more than they reveal.
  </p>

  <p>
    Precision matters. Without it, public discourse on AI will continue to drift toward 
    confusion—rather than understanding.
  </p>
</article>
<article class="post">
<div class="post-meta">Teaching & Research </div>
<h3>Teacher, Entertainer, Babysitter: The Hidden Triple Threat in Academia</h3>
<div class="post-date">December 1, 2025</div>
<p>
  In <a href="https://www.janrecker.com/this-is-research-podcast/managing-academics-is-like-herding-cats-19-november-2025/">
    a recent episode of <i>This IS Research</i> Podcast,
  </a> one of the co-hosts argued that a “superstar” professor in any field should not be teaching freshman classes. According to him, teaching first-year students requires nothing more than a blend of teacher, entertainer, and babysitter—hardly a good use of a superstar’s time.
</p>
<p>
Perhaps society <i>does</i> benefit when its academic superstars devote most of their energy to research. Even if we grant that possibility, isn’t that supposedly “simple” blend—a teacher, an entertainer, and a babysitter—actually a remarkable combination? I have rarely met individuals who genuinely possess this mix of skill, charisma, and patience.
</p>
<p>
If you are one of them, you bring tremendous value—especially now, as colleges confront the so-called demographic cliff. Your work with first-year students is not trivial; it is indispensable.
</p>

</article> 
<article class="post">
<div class="post-meta">Life · Perspective</div>
<h3>Why “Different” Is the Default, Not the Insight</h3>
<div class="post-date">November 26, 2025</div>
 <p>
    I recently read 
    <strong>
      “<a href="https://sloanreview.mit.edu/article/agentic-ai-at-scale-redefining-management-for-a-superhuman-workforce/" target="_blank" rel="noopener noreferrer">
        Agentic AI at Scale: Redefining Management for a Superhuman Workforce
      </a>”
    </strong>
    in <em>MIT Sloan Management Review</em>. The article notes that 
    nearly 70% of surveyed experts claim that agentic AI accountability demands entirely new management approaches, while 25% disagree. I applaud the minority.
  </p>

  <p>
    It is remarkably easy to label every new invention as fundamentally different. We do it because:
  </p>

  <ol>
    <li>
      <strong>Novelty is socially inherited, not independently concluded.</strong><br>
      Experts and observers often believe a technology is new because they 
      <strong>heard others say it is</strong>. Repetition manufactures inevitability.
    </li>
    <li>
      <strong>Agreement is cognitively and reputationally cheap.</strong><br>
      Conforming to the majority is easier than resisting it.
    </li>
    <li>
      <strong>Continuity requires proof; difference requires none.</strong><br>
      Declaring “difference”&mdash;the popular choice&mdash;invites little challenge. 
      Declaring continuity flips the burden: <strong>you must defend it</strong>. 
      In a low-attention, high-velocity world, most avoid the cost.
    </li>
  </ol>

  <p>
    Difference is often not insight&mdash;it’s <strong>echo, convenience, and safety in disguise</strong>. 
    That alone makes it worth interrogating.
  </p>
</article>    
<article class="post">
<div class="post-meta">Research · Reflections</div>
<h3>Doing Slow Work in a Fast Digital World</h3>
<div class="post-date">November 24, 2025</div>
<p>
            Much of my research looks at very fast phenomena—tweets, platform
            launches, market reactions. Yet the work itself is slow. Data
            collection, coding, theorizing, and revising a paper over many years
            can feel out of sync with the speed of digital life.
          </p>
<p>
            I have come to see this tension as a feature, not a bug. Slowness
            gives us room to notice patterns that are invisible in the moment
            and to question “obvious” narratives. It is one way academia can add
            value in a world flooded with instant commentary.
          </p>
</article>

<article class="post">
<div class="post-meta">Life · Perspective</div>
<h3>First-Generation Paths and Paying It Forward</h3>
<div class="post-date">November 24, 2025</div>
<p>
            As a first-generation college graduate, I still remember how opaque
            universities felt when I was a student. Many unwritten rules were
            confusing, and chances to “get involved” or “network” did not feel
            designed with students like me in mind.
          </p>
<p>
            That memory shapes how I advise and teach. I try to make expectations
            explicit, open doors to research and projects, and remind students
            that their background is not a deficit but a source of insight.
            Education works best when it makes more future paths visible, not
            fewer.
          </p>
</article>
</div>
</section>
<section>
<h2>Notes to Future Posts</h2>
<p>
        A few themes I expect to write more about here:
      </p>
<ul class="card-list">
<li>How AI is changing both what we research and how we research it.</li>
<li>What “good” digital citizenship might look like for organizations.</li>
<li>Practical advice for students navigating analytics and tech careers.</li>
<li>Small habits that make academic work more sustainable and humane.</li>
</ul>
<p style="margin-top:0.6rem;">
        If there is a topic you would like to see me reflect on, you are welcome
        to reach out at <a href="mailto:i.kim@unh.edu">i.kim@unh.edu</a>.
      </p>
</section>
</main>
<footer>
    © <span id="year"></span> Inchan Kim. All rights reserved.
  </footer>
<script>
    document.getElementById("year").textContent = new Date().getFullYear();
  </script>
</body>
</html>
